submit host:
login1
submit dir:
/lustre/home/cgerlach/unet_seismic_new
nodelist:
fj[164-171]
Loading pytorch/arm22/1.10
  Loading requirement: arm-modules/22.0 binutils/11.2.0 acfl/22.0.1
    /lustre/software/arm/compiler/22.0/moduledeps/acfl/22.0.1/armpl/22.0.1
    ucx/1.11.2 openmpi/arm22.0/4.1.2
[fj164:1456268] MCW rank 0 bound to socket 0[core 0[hwt 0]], socket 0[core 1[hwt 0]], socket 0[core 2[hwt 0]], socket 0[core 3[hwt 0]], socket 0[core 4[hwt 0]], socket 0[core 5[hwt 0]], socket 0[core 6[hwt 0]], socket 0[core 7[hwt 0]], socket 0[core 8[hwt 0]], socket 0[core 9[hwt 0]], socket 0[core 10[hwt 0]], socket 0[core 11[hwt 0]]: [B/B/B/B/B/B/B/B/B/B/B/B][./././././././././././.][./././././././././././.][./././././././././././.]
[fj164:1456268] MCW rank 1 bound to socket 1[core 12[hwt 0]], socket 1[core 13[hwt 0]], socket 1[core 14[hwt 0]], socket 1[core 15[hwt 0]], socket 1[core 16[hwt 0]], socket 1[core 17[hwt 0]], socket 1[core 18[hwt 0]], socket 1[core 19[hwt 0]], socket 1[core 20[hwt 0]], socket 1[core 21[hwt 0]], socket 1[core 22[hwt 0]], socket 1[core 23[hwt 0]]: [./././././././././././.][B/B/B/B/B/B/B/B/B/B/B/B][./././././././././././.][./././././././././././.]
[fj164:1456268] MCW rank 2 bound to socket 2[core 24[hwt 0]], socket 2[core 25[hwt 0]], socket 2[core 26[hwt 0]], socket 2[core 27[hwt 0]], socket 2[core 28[hwt 0]], socket 2[core 29[hwt 0]], socket 2[core 30[hwt 0]], socket 2[core 31[hwt 0]], socket 2[core 32[hwt 0]], socket 2[core 33[hwt 0]], socket 2[core 34[hwt 0]], socket 2[core 35[hwt 0]]: [./././././././././././.][./././././././././././.][B/B/B/B/B/B/B/B/B/B/B/B][./././././././././././.]
[fj164:1456268] MCW rank 3 bound to socket 3[core 36[hwt 0]], socket 3[core 37[hwt 0]], socket 3[core 38[hwt 0]], socket 3[core 39[hwt 0]], socket 3[core 40[hwt 0]], socket 3[core 41[hwt 0]], socket 3[core 42[hwt 0]], socket 3[core 43[hwt 0]], socket 3[core 44[hwt 0]], socket 3[core 45[hwt 0]], socket 3[core 46[hwt 0]], socket 3[core 47[hwt 0]]: [./././././././././././.][./././././././././././.][./././././././././././.][B/B/B/B/B/B/B/B/B/B/B/B]
[fj165:1606085] MCW rank 4 bound to socket 0[core 0[hwt 0]], socket 0[core 1[hwt 0]], socket 0[core 2[hwt 0]], socket 0[core 3[hwt 0]], socket 0[core 4[hwt 0]], socket 0[core 5[hwt 0]], socket 0[core 6[hwt 0]], socket 0[core 7[hwt 0]], socket 0[core 8[hwt 0]], socket 0[core 9[hwt 0]], socket 0[core 10[hwt 0]], socket 0[core 11[hwt 0]]: [B/B/B/B/B/B/B/B/B/B/B/B][./././././././././././.][./././././././././././.][./././././././././././.]
[fj165:1606085] MCW rank 5 bound to socket 1[core 12[hwt 0]], socket 1[core 13[hwt 0]], socket 1[core 14[hwt 0]], socket 1[core 15[hwt 0]], socket 1[core 16[hwt 0]], socket 1[core 17[hwt 0]], socket 1[core 18[hwt 0]], socket 1[core 19[hwt 0]], socket 1[core 20[hwt 0]], socket 1[core 21[hwt 0]], socket 1[core 22[hwt 0]], socket 1[core 23[hwt 0]]: [./././././././././././.][B/B/B/B/B/B/B/B/B/B/B/B][./././././././././././.][./././././././././././.]
[fj165:1606085] MCW rank 6 bound to socket 2[core 24[hwt 0]], socket 2[core 25[hwt 0]], socket 2[core 26[hwt 0]], socket 2[core 27[hwt 0]], socket 2[core 28[hwt 0]], socket 2[core 29[hwt 0]], socket 2[core 30[hwt 0]], socket 2[core 31[hwt 0]], socket 2[core 32[hwt 0]], socket 2[core 33[hwt 0]], socket 2[core 34[hwt 0]], socket 2[core 35[hwt 0]]: [./././././././././././.][./././././././././././.][B/B/B/B/B/B/B/B/B/B/B/B][./././././././././././.]
[fj165:1606085] MCW rank 7 bound to socket 3[core 36[hwt 0]], socket 3[core 37[hwt 0]], socket 3[core 38[hwt 0]], socket 3[core 39[hwt 0]], socket 3[core 40[hwt 0]], socket 3[core 41[hwt 0]], socket 3[core 42[hwt 0]], socket 3[core 43[hwt 0]], socket 3[core 44[hwt 0]], socket 3[core 45[hwt 0]], socket 3[core 46[hwt 0]], socket 3[core 47[hwt 0]]: [./././././././././././.][./././././././././././.][./././././././././././.][B/B/B/B/B/B/B/B/B/B/B/B]
##############################################
# Welcome to EML's U-Net for seismic example #
##############################################
could not find a CUDA device
printing configuration:
{
  "unet": {
    "n_init_channels": 32,
    "kernel_size": 3,
    "n_layers_per_block": 2,
    "n_levels": 2
  },
  "train": {
    "data": {
      "seismic": "data/data_train.npz",
      "labels": "data/labels_train.npz",
      "sample_shape": [
        1004,
        1,
        588
      ],
      "subset": [
        [
          0,
          1004
        ],
        [
          0,
          750
        ],
        [
          0,
          588
        ]
      ]
    },
    "n_epochs": 20,
    "n_epochs_print": 5,
    "n_batch_abort": 5000,
    "batch_size": 16
  },
  "test": {
    "data": {
      "seismic": "data/data_train.npz",
      "labels": "data/labels_train.npz",
      "sample_shape": [
        1004,
        1,
        588
      ],
      "subset": [
        [
          0,
          1004
        ],
        [
          751,
          782
        ],
        [
          0,
          588
        ]
      ]
    },
    "batch_size": 8
  }
}
********************
* assembling U-Net *
********************
encoder:
Sequential(
  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (5): ReLU(inplace=True)
)
max_pooling:
MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
crop:
ZeroPad2d(padding=(-4, -4, -4, -4), value=0.0)
bottleneck:
Sequential(
  (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (5): ReLU(inplace=True)
)
up_sampling:
Upsample(scale_factor=2.0, mode=bilinear)
decoder:
Sequential(
  (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (5): ReLU(inplace=True)
)
classification:
Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))
*****************
* prepping data *
*****************
loading training dataset
shape padded:(1004, 750, 588)
shape:(1, 750, 1)
loading test data set
shape padded:(1004, 31, 588)
shape:(1, 31, 1)
deriving mean and standard deviation of training data
  mean: 0.6930369
  std: 388.38947
normalizing training and test data
initializing data loaders
************
* training *
************
training epoch1
  processed 47 batches
  training loss:tensor(2.0384)
applying net to test data
  test loss:tensor(2.0579)
  test accuracy:tensor(0.1351)
training epoch2
  processed 47 batches
  training loss:tensor(1.9432)
applying net to test data
  test loss:tensor(1.9634)
  test accuracy:tensor(0.1781)
training epoch3
  processed 47 batches
  training loss:tensor(1.8590)
applying net to test data
  test loss:tensor(1.8772)
  test accuracy:tensor(0.2002)
training epoch4
  processed 47 batches
  training loss:tensor(1.7864)
applying net to test data
  test loss:tensor(1.8027)
  test accuracy:tensor(0.2151)
training epoch5
  processed 47 batches
  training loss:tensor(1.7226)
applying net to test data
  test loss:tensor(1.7382)
  test accuracy:tensor(0.2255)
training epoch6
  processed 47 batches
  training loss:tensor(1.6649)
applying net to test data
  test loss:tensor(1.6815)
  test accuracy:tensor(0.2332)
training epoch7
  processed 47 batches
  training loss:tensor(1.6129)
applying net to test data
  test loss:tensor(1.6316)
  test accuracy:tensor(0.2387)
training epoch8
  processed 47 batches
  training loss:tensor(1.5657)
applying net to test data
  test loss:tensor(1.5873)
  test accuracy:tensor(0.2433)
training epoch9
  processed 47 batches
  training loss:tensor(1.5227)
applying net to test data
  test loss:tensor(1.5474)
  test accuracy:tensor(0.2473)
training epoch10
  processed 47 batches
  training loss:tensor(1.4836)
applying net to test data
  test loss:tensor(1.5115)
  test accuracy:tensor(0.2509)
training epoch11
  processed 47 batches
  training loss:tensor(1.4478)
applying net to test data
  test loss:tensor(1.4790)
  test accuracy:tensor(0.2542)
training epoch12
  processed 47 batches
  training loss:tensor(1.4151)
applying net to test data
  test loss:tensor(1.4493)
  test accuracy:tensor(0.2573)
training epoch13
  processed 47 batches
  training loss:tensor(1.3851)
applying net to test data
  test loss:tensor(1.4223)
  test accuracy:tensor(0.2603)
training epoch14
  processed 47 batches
  training loss:tensor(1.3575)
applying net to test data
  test loss:tensor(1.3976)
  test accuracy:tensor(0.2630)
training epoch15
  processed 47 batches
  training loss:tensor(1.3322)
applying net to test data
  test loss:tensor(1.3750)
  test accuracy:tensor(0.2654)
training epoch16
  processed 47 batches
  training loss:tensor(1.3087)
applying net to test data
  test loss:tensor(1.3543)
  test accuracy:tensor(0.2676)
training epoch17
  processed 47 batches
  training loss:tensor(1.2871)
applying net to test data
  test loss:tensor(1.3351)
  test accuracy:tensor(0.2697)
training epoch18
  processed 47 batches
  training loss:tensor(1.2670)
applying net to test data
  test loss:tensor(1.3174)
  test accuracy:tensor(0.2717)
training epoch19
  processed 47 batches
  training loss:tensor(1.2483)
applying net to test data
  test loss:tensor(1.3009)
  test accuracy:tensor(0.2734)
training epoch20
  processed 47 batches
  training loss:tensor(1.2309)
applying net to test data
  test loss:tensor(1.2857)
  test accuracy:tensor(0.2750)

... Run took 1774 seconds.

